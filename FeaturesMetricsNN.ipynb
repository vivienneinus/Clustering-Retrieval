{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('D:/Downloads/vivienne/ML/Clustering&Retrieval_UW')\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.sparse import csr_matrix # sparse matrices\n",
    "\n",
    "#Load in the dataset\n",
    "wiki = pd.read_csv('people_wiki.csv')\n",
    "\n",
    "#Extract word count vectors\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    \n",
    "    return csr_matrix( (data, indices, indptr), shape)\n",
    "\n",
    "word_count = load_sparse_csr('people_wiki_word_count.npz')\n",
    "with open('people_wiki_map_index_to_word.json') as file:    \n",
    "    map_index_to_word = json.load(file)\n",
    "\n",
    "#Find nearest neighbors using word count vectors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model = NearestNeighbors(metric='euclidean', algorithm='brute')\n",
    "model.fit(word_count)\n",
    "\n",
    "print(wiki[wiki['name'] == 'Barack Obama'])\n",
    "#1st arg: word count vector\n",
    "distances, indices = model.kneighbors(word_count[35817], n_neighbors=10)\n",
    "\n",
    "neighbors = pd.DataFrame(data={'distance':distances.flatten()},\n",
    "                               index=indices.flatten())\n",
    "#display the query results, the indices of and distances to the 10 NN\n",
    "print(wiki.join(neighbors).sort_values(by = 'distance', ascending = True)\\\n",
    "      [['name','distance']][0:10])\n",
    "\n",
    "#Interpret the nearest neighbors\n",
    "def unpack_dict(matrix, map_index_to_word):\n",
    "    table = sorted(map_index_to_word, key=map_index_to_word.get)\n",
    "        \n",
    "    data = matrix.data\n",
    "    indices = matrix.indices\n",
    "    indptr = matrix.indptr\n",
    "    \n",
    "    num_doc = matrix.shape[0]\n",
    "\n",
    "    return [{k:v for k,v in zip([table[word_id] for word_id in \\\n",
    "                                 indices[indptr[i]:indptr[i+1]] ], \\\n",
    "                                 data[indptr[i]:indptr[i+1]].tolist())} \\\n",
    "            for i in range(num_doc) ]\n",
    "\n",
    "wiki['word_count'] = unpack_dict(word_count, map_index_to_word)\n",
    "\n",
    "#A utility function displays a dictionary in tabular form\n",
    "def top_words(name):\n",
    "    \"\"\"\n",
    "    Get a table of the most frequent words in the given person's wikipedia \n",
    "    page.\n",
    "    \"\"\"\n",
    "    row = wiki[wiki['name'] == name]\n",
    "    dict_word_count = row['word_count'].iloc[0]\n",
    "    word_count_table = pd.DataFrame(dict_word_count.items(), \n",
    "                                    columns=['word','count'])\n",
    "    word_count_table = word_count_table.sort_values(by='count', \n",
    "                                                    ascending=False)\n",
    "    return word_count_table\n",
    "\n",
    "obama_words = top_words('Barack Obama')\n",
    "print(obama_words)\n",
    "\n",
    "barrio_words = top_words('Francisco Barrio')\n",
    "print(barrio_words)\n",
    "\n",
    "combined_words = obama_words.join(barrio_words, on='word')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
